{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup Instructions\n",
    "\n",
    "To set up the environment and install the required dependencies, run the following commands in your terminal:\n",
    "\n",
    "```bash\n",
    "# Create a new conda environment\n",
    "conda env create -f environment_mangosense.yml \n",
    "\n",
    "# Activate the environment\n",
    "conda activate mangosense\n",
    "\n",
    "# Install YOLO (Ultralytics)\n",
    "pip install ultralytics\n",
    "\n",
    "# Clone the Segment Anything repository\n",
    "git clone https://github.com/facebookresearch/segment-anything.git\n",
    "\n",
    "# Navigate into the repository\n",
    "cd segment-anything\n",
    "\n",
    "# Install Segment Anything in editable mode\n",
    "pip install -e .\n",
    "\n",
    "# Install additional dependencies\n",
    "pip install shapely\n",
    "\n",
    "pip install tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Requirements Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell to check the necessory packages in your env.\n",
    "from shapely.geometry import Polygon                                #shapely=2.0.4=pypi_0\n",
    "import cv2                                                          #opencv-python=4.9.0.80=pypi_0\n",
    "import numpy as np                                                  #python=3.12.0=hab00c5b_0_cpython,   numpy=1.26.4=pypi_0\n",
    "import matplotlib.pyplot as plt                                     #matplotlib=3.9.0=pypi_0\n",
    "import torch                                                        #torch=2.3.0=pypi_0       torchvision=0.18.0=pypi_0\n",
    "from ultralytics import YOLO                                        #ultralytics=8.2.18=pypi_0\n",
    "from segment_anything import SamPredictor, sam_model_registry       #segment-anything=1.0=pypi_0\n",
    "from tqdm import tqdm                                               #tqdm=4.66.4=pypi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "from statistics import mean\n",
    "from PIL import Image\n",
    "from pathlib import Path \n",
    "import json\n",
    "from shapely.geometry import Polygon, box\n",
    "from shapely.validation import explain_validity\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import random\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import ast\n",
    "import argparse \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. YoLo model fine tunning using available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving JSON files to: image_wise_json_after_cvat_manual_annotation\n",
      "07_01_01.json file created successfully!\n",
      "07_01_02.json file created successfully!\n",
      "07_01_03.json file created successfully!\n",
      "07_01_04.json file created successfully!\n",
      "07_01_05.json file created successfully!\n",
      "07_01_06.json file created successfully!\n",
      "07_01_07.json file created successfully!\n",
      "07_01_08.json file created successfully!\n",
      "07_02_01.json file created successfully!\n",
      "07_02_02.json file created successfully!\n",
      "07_02_03.json file created successfully!\n",
      "07_02_04.json file created successfully!\n",
      "07_02_05.json file created successfully!\n",
      "07_02_06.json file created successfully!\n",
      "07_02_07.json file created successfully!\n",
      "07_02_08.json file created successfully!\n",
      "07_03_01.json file created successfully!\n",
      "07_03_02.json file created successfully!\n",
      "07_03_03.json file created successfully!\n",
      "07_03_04.json file created successfully!\n",
      "07_03_05.json file created successfully!\n",
      "07_03_06.json file created successfully!\n",
      "07_03_07.json file created successfully!\n",
      "07_03_08.json file created successfully!\n",
      "07_04_01.json file created successfully!\n",
      "07_04_02.json file created successfully!\n",
      "07_04_03.json file created successfully!\n",
      "07_04_04.json file created successfully!\n",
      "07_04_05.json file created successfully!\n",
      "07_04_06.json file created successfully!\n",
      "07_04_07.json file created successfully!\n",
      "07_04_08.json file created successfully!\n",
      "07_05_01.json file created successfully!\n",
      "07_05_02.json file created successfully!\n",
      "07_05_03.json file created successfully!\n",
      "07_05_04.json file created successfully!\n",
      "07_05_05.json file created successfully!\n",
      "07_05_06.json file created successfully!\n",
      "07_05_07.json file created successfully!\n",
      "07_05_08.json file created successfully!\n",
      "07_06_01.json file created successfully!\n",
      "07_06_02.json file created successfully!\n",
      "07_06_03.json file created successfully!\n",
      "07_06_04.json file created successfully!\n",
      "07_06_05.json file created successfully!\n",
      "07_06_06.json file created successfully!\n",
      "07_06_07.json file created successfully!\n",
      "07_06_08.json file created successfully!\n",
      "07_07_01.json file created successfully!\n",
      "07_07_02.json file created successfully!\n",
      "07_07_03.json file created successfully!\n",
      "07_07_04.json file created successfully!\n",
      "07_07_05.json file created successfully!\n",
      "07_07_06.json file created successfully!\n",
      "07_07_07.json file created successfully!\n",
      "07_07_08.json file created successfully!\n",
      "07_08_01.json file created successfully!\n",
      "07_08_02.json file created successfully!\n",
      "07_08_03.json file created successfully!\n",
      "07_08_04.json file created successfully!\n",
      "07_08_05.json file created successfully!\n",
      "07_08_06.json file created successfully!\n",
      "07_08_07.json file created successfully!\n",
      "07_08_08.json file created successfully!\n",
      "07_09_01.json file created successfully!\n",
      "07_09_02.json file created successfully!\n",
      "07_09_03.json file created successfully!\n",
      "07_09_04.json file created successfully!\n",
      "07_09_05.json file created successfully!\n",
      "07_09_06.json file created successfully!\n",
      "07_09_07.json file created successfully!\n",
      "07_09_08.json file created successfully!\n",
      "07_10_01.json file created successfully!\n",
      "07_10_02.json file created successfully!\n",
      "07_10_03.json file created successfully!\n",
      "07_10_04.json file created successfully!\n",
      "07_10_05.json file created successfully!\n",
      "07_10_06.json file created successfully!\n",
      "07_10_07.json file created successfully!\n",
      "07_10_08.json file created successfully!\n",
      "07_11_01.json file created successfully!\n",
      "07_11_02.json file created successfully!\n",
      "07_11_03.json file created successfully!\n",
      "07_11_04.json file created successfully!\n",
      "07_11_05.json file created successfully!\n",
      "07_11_06.json file created successfully!\n",
      "07_11_07.json file created successfully!\n",
      "07_11_08.json file created successfully!\n",
      "07_12_01.json file created successfully!\n",
      "07_12_02.json file created successfully!\n",
      "07_12_03.json file created successfully!\n",
      "07_12_04.json file created successfully!\n",
      "07_12_05.json file created successfully!\n",
      "07_12_06.json file created successfully!\n",
      "07_12_07.json file created successfully!\n",
      "07_12_08.json file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# The json file contain all the images annotations -> instances_default_visit_07.json\n",
    "# Now it will converted to image wise annotation files and save into the 'image_wise_json_after_cvat_manual_annotation' path\n",
    "!python yolo_fine_tune/1_all_annotation_json_to_imagewise_json.py 'instances_default_visit_07.json' 'image_wise_json_after_cvat_manual_annotation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Image:07_01_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "1it [00:04,  4.89s/it]Image:07_01_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "2it [00:08,  4.05s/it]Image:07_01_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "3it [00:11,  3.81s/it]Image:07_01_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "4it [00:15,  3.67s/it]Image:07_01_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "5it [00:18,  3.57s/it]Image:07_01_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "6it [00:22,  3.55s/it]Image:07_01_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "7it [00:25,  3.54s/it]Image:07_01_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "8it [00:29,  3.57s/it]Image:07_02_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "9it [00:33,  3.64s/it]Image:07_02_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "10it [00:36,  3.49s/it]Image:07_02_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "11it [00:39,  3.48s/it]Image:07_02_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "12it [00:43,  3.44s/it]Image:07_02_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "13it [00:46,  3.45s/it]Image:07_02_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "14it [00:50,  3.55s/it]Image:07_02_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "15it [00:54,  3.59s/it]Image:07_02_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "16it [00:57,  3.68s/it]Image:07_03_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "17it [01:01,  3.55s/it]Image:07_03_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "18it [01:04,  3.55s/it]Image:07_03_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "19it [01:08,  3.51s/it]Image:07_03_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "20it [01:11,  3.59s/it]Image:07_03_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "21it [01:15,  3.70s/it]Image:07_03_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "22it [01:19,  3.65s/it]Image:07_03_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "23it [01:22,  3.48s/it]Image:07_03_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "24it [01:25,  3.38s/it]Image:07_04_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "25it [01:29,  3.42s/it]Image:07_04_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "26it [01:32,  3.43s/it]Image:07_04_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "27it [01:36,  3.56s/it]Image:07_04_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "28it [01:40,  3.54s/it]Image:07_04_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "29it [01:43,  3.64s/it]Image:07_04_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "30it [01:47,  3.72s/it]Image:07_04_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "31it [01:51,  3.61s/it]Image:07_04_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "32it [01:54,  3.56s/it]Image:07_05_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "33it [01:58,  3.55s/it]Image:07_05_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "34it [02:01,  3.60s/it]Image:07_05_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "35it [02:05,  3.68s/it]Image:07_05_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "36it [02:09,  3.78s/it]Image:07_05_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "37it [02:13,  3.65s/it]Image:07_05_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "38it [02:16,  3.65s/it]Image:07_05_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "39it [02:20,  3.61s/it]Image:07_05_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "40it [02:23,  3.58s/it]Image:07_06_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "41it [02:27,  3.70s/it]Image:07_06_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "42it [02:31,  3.85s/it]Image:07_06_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "43it [02:36,  4.05s/it]Image:07_06_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "44it [02:41,  4.23s/it]Image:07_06_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "45it [02:45,  4.20s/it]Image:07_06_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "46it [02:49,  4.20s/it]Image:07_06_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "47it [02:53,  4.25s/it]Image:07_06_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "48it [02:58,  4.32s/it]Image:07_07_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "49it [03:01,  4.13s/it]Image:07_07_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "50it [03:05,  4.08s/it]Image:07_07_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "51it [03:10,  4.13s/it]Image:07_07_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "52it [03:14,  4.09s/it]Image:07_07_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "53it [03:18,  4.15s/it]Image:07_07_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "54it [03:22,  4.16s/it]Image:07_07_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "55it [03:26,  4.11s/it]Image:07_07_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "56it [03:30,  3.92s/it]Image:07_08_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "57it [03:33,  3.79s/it]Image:07_08_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "58it [03:37,  3.78s/it]Image:07_08_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "59it [03:41,  3.80s/it]Image:07_08_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "60it [03:45,  3.83s/it]Image:07_08_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "61it [03:49,  3.88s/it]Image:07_08_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "62it [03:52,  3.84s/it]Image:07_08_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "63it [03:56,  3.71s/it]Image:07_08_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "64it [03:59,  3.64s/it]Image:07_09_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "65it [04:03,  3.79s/it]Image:07_09_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "66it [04:08,  3.94s/it]Image:07_09_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "67it [04:12,  4.11s/it]Image:07_09_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "68it [04:17,  4.26s/it]Image:07_09_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "69it [04:21,  4.30s/it]Image:07_09_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "70it [04:25,  4.19s/it]Image:07_09_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "71it [04:29,  4.01s/it]Image:07_09_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "72it [04:32,  3.95s/it]Image:07_10_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "73it [04:37,  4.00s/it]Image:07_10_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "74it [04:41,  4.20s/it]Image:07_10_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "75it [04:45,  4.14s/it]Image:07_10_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "76it [04:49,  4.03s/it]Image:07_10_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "77it [04:54,  4.19s/it]Image:07_10_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "78it [04:58,  4.16s/it]Image:07_10_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "79it [05:01,  4.02s/it]Image:07_10_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "80it [05:05,  4.01s/it]Image:07_11_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "81it [05:09,  3.90s/it]Image:07_11_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "82it [05:13,  3.86s/it]Image:07_11_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "83it [05:17,  3.87s/it]Image:07_11_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "84it [05:21,  3.90s/it]Image:07_11_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "85it [05:25,  3.91s/it]Image:07_11_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "86it [05:29,  3.92s/it]Image:07_11_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "87it [05:32,  3.87s/it]Image:07_11_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "88it [05:36,  3.76s/it]Image:07_12_01  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "89it [05:40,  3.77s/it]Image:07_12_02  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "90it [05:44,  3.87s/it]Image:07_12_03  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "91it [05:48,  3.98s/it]Image:07_12_04  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "92it [05:52,  4.06s/it]Image:07_12_05  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "93it [05:56,  4.11s/it]Image:07_12_06  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "94it [06:00,  4.07s/it]Image:07_12_07  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "95it [06:04,  3.93s/it]Image:07_12_08  Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "96it [06:08,  3.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# 'visit_07_04232024'-> image folder\n",
    "# From the annotations the bbox are generated for the images\n",
    "# The images size is 8000x6000, so we devided them in the patches of 1000x1000\n",
    "# The bbox and the patchs of images are stored in the given folder 'yolo_train_visit_07'\n",
    "!python yolo_fine_tune/2_yolo_train_data_preparation.py 'visit_07_04232024' 'yolo_train_visit_07' #change the input_dir_path visit_02_02282024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete. Train images: 3686, Validation images: 922\n"
     ]
    }
   ],
   "source": [
    "# Devide the data in the train and test\n",
    "# here 80% will be train data and 20% test data\n",
    "!python yolo_fine_tune/2_yolo_train_test_split.py 'yolo_train_visit_07' '80' #create yolo_train_visit_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file saved at yolo_train_visit_07/data_config.yaml\n"
     ]
    }
   ],
   "source": [
    "# below contenet is for the data_config_file\n",
    "# it will be inside the data folder for our implementation, the file will be in .yaml format \n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# data config details\n",
    "data_config = {\n",
    "    \"path\": \"/user/data/YOLO_SAM_pipeline/yolo_train_visit_07\",\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\": \"images/val\",\n",
    "    \"nc\": 2,\n",
    "    \"names\": {\n",
    "        0: \"flower\",\n",
    "        1: \"fruitlet\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# save directory (inside data folder)\n",
    "save_dir = Path(\"yolo_train_visit_07\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save file path\n",
    "yaml_path = save_dir / \"data_config.yaml\"\n",
    "\n",
    "# save yaml\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(data_config, f, sort_keys=False)\n",
    "\n",
    "print(f\"YAML file saved at {yaml_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.204 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.109 ðŸš€ Python-3.12.8 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16101MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=yolo_train_visit_07/data_config.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/.config/Ultralytics/Arial.ttf'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 881kB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 6.46MB/s]\n",
      ..........................................................
      "Plotting labels to runs/detect/train6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train6\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100       2.1G      1.248      3.217      1.185         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.493      0.362      0.331      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      2.43G      1.293      2.248      1.189         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.446      0.388      0.377       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      2.45G      1.332      1.936      1.203         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.381      0.334      0.342      0.218\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      2.46G      1.309      1.841      1.218          4        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.406      0.398       0.37       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      2.48G      1.265      1.713      1.193          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.465      0.336      0.362      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100       2.5G      1.221      1.592      1.161         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.506      0.417      0.387      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      2.51G      1.211        1.6      1.161          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.545      0.473      0.477      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      2.53G      1.195      1.549       1.16          1        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.877      0.286      0.417      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      2.54G      1.181      1.549      1.147          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.533      0.451      0.461      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      2.56G      1.152      1.473      1.138          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.495      0.452      0.473      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      2.58G      1.149      1.445      1.141          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.526      0.483      0.484      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100       2.6G      1.103      1.428      1.126          4        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116       0.52      0.514      0.521      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      2.62G      1.093      1.365      1.119          7        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.488      0.497      0.499      0.337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      2.62G      1.065      1.324      1.105          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.564      0.501      0.534      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      2.65G      1.081      1.329      1.109          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.561      0.523      0.521      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      2.67G      1.089      1.359      1.106         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.533      0.526      0.502      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      2.68G      1.082      1.349      1.093         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.509      0.486      0.495      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      2.69G      1.046       1.28      1.094          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.561      0.506      0.524      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      2.72G      1.051      1.296      1.089          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.559      0.498      0.527      0.361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      2.73G      1.041      1.286       1.09          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.528      0.532      0.524      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      2.75G      1.029       1.29       1.08         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.539       0.49      0.516      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      2.76G      1.048      1.269      1.077          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.608      0.504      0.527      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      2.78G      1.031      1.217      1.076         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.556      0.549      0.548      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100       2.8G      1.053      1.281      1.093          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.543      0.503      0.517      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      2.82G      1.013       1.22      1.072          4        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.586      0.546      0.549      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      2.83G      1.023      1.213      1.084          1        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.548      0.543      0.574      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      2.85G       1.03      1.216      1.076         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.599       0.52      0.549      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      2.87G     0.9979       1.22      1.067          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.541      0.545      0.576      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      2.88G     0.9805      1.182      1.052         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.635      0.516      0.569      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100       2.9G      1.013        1.2      1.061         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.612      0.575      0.573      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      2.92G      1.004      1.173      1.064          7        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.559      0.562      0.579       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      2.94G      0.998      1.168      1.057          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.596      0.547      0.579      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      2.95G      1.007      1.164      1.066         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.536       0.54      0.569      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      2.97G     0.9916      1.136      1.054          2        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116      0.492      0.552      0.538      0.378\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100      2.99G     0.9673      1.136       1.05          6        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        922       1116       0.66      0.536      0.615      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100         3G       1.01      1.296      1.103         16        640:  \n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# here '07' is visit name which help to get the data config file path\n",
    "# the given .pt file path is to load any pretrained model\n",
    "!python yolo_fine_tune/3_yolo_fine_tune.py --config yolo_train_visit_07/data_config.yaml --weights yolov8n.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating Annotations for new images using YOLO+SAM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the SAM weights for the sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08_01_01 started............\n",
      "Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "image splited in 48 patches and saved in split_images.\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 1.8ms\n",
      "1: 640x640 (no detections), 1.8ms\n",
      "2: 640x640 (no detections), 1.8ms\n",
      "3: 640x640 (no detections), 1.8ms\n",
      "4: 640x640 (no detections), 1.8ms\n",
      "5: 640x640 (no detections), 1.8ms\n",
      "6: 640x640 (no detections), 1.8ms\n",
      "7: 640x640 (no detections), 1.8ms\n",
      "8: 640x640 1 fruitlet, 1.8ms\n",
      "9: 640x640 (no detections), 1.8ms\n",
      "10: 640x640 1 fruitlet, 1.8ms\n",
      "11: 640x640 (no detections), 1.8ms\n",
      "12: 640x640 (no detections), 1.8ms\n",
      "13: 640x640 2 fruitlets, 1.8ms\n",
      "14: 640x640 5 fruitlets, 1.8ms\n",
      "15: 640x640 1 fruitlet, 1.8ms\n",
      "16: 640x640 (no detections), 1.8ms\n",
      "17: 640x640 1 flower, 1.8ms\n",
      "18: 640x640 3 fruitlets, 1.8ms\n",
      "19: 640x640 2 fruitlets, 1.8ms\n",
      "20: 640x640 3 fruitlets, 1.8ms\n",
      "21: 640x640 7 fruitlets, 1.8ms\n",
      "22: 640x640 2 fruitlets, 1.8ms\n",
      "23: 640x640 (no detections), 1.8ms\n",
      "24: 640x640 4 fruitlets, 1.8ms\n",
      "25: 640x640 4 fruitlets, 1.8ms\n",
      "26: 640x640 (no detections), 1.8ms\n",
      "27: 640x640 (no detections), 1.8ms\n",
      "28: 640x640 (no detections), 1.8ms\n",
      "29: 640x640 1 fruitlet, 1.8ms\n",
      "30: 640x640 4 fruitlets, 1.8ms\n",
      "31: 640x640 3 fruitlets, 1.8ms\n",
      "32: 640x640 1 fruitlet, 1.8ms\n",
      "33: 640x640 (no detections), 1.8ms\n",
      "34: 640x640 (no detections), 1.8ms\n",
      "35: 640x640 (no detections), 1.8ms\n",
      "36: 640x640 (no detections), 1.8ms\n",
      "37: 640x640 (no detections), 1.8ms\n",
      "38: 640x640 (no detections), 1.8ms\n",
      "39: 640x640 (no detections), 1.8ms\n",
      "40: 640x640 (no detections), 1.8ms\n",
      "41: 640x640 (no detections), 1.8ms\n",
      "42: 640x640 (no detections), 1.8ms\n",
      "43: 640x640 (no detections), 1.8ms\n",
      "44: 640x640 (no detections), 1.8ms\n",
      "45: 640x640 (no detections), 1.8ms\n",
      "46: 640x640 (no detections), 1.8ms\n",
      "47: 640x640 (no detections), 1.8ms\n",
      "Speed: 2.5ms preprocess, 1.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "YOLO predicted BBOX for all patches and saved successfully in yolo_out_for_image_bbox_data.json.\n",
      "\n",
      "Bounding boxes merged and saved to yolo_out_for_image_bbox_data.json.\n",
      "\n",
      "SAM generated the mask for all patches and saved to polygons.json\n",
      "\n",
      "1 18\n",
      "2 18\n",
      "3 18\n",
      "4 18\n",
      "1 20\n",
      "2 20\n",
      "3 20\n",
      "4 20\n",
      "1 23\n",
      "2 23\n",
      "index_right: 23 1\n",
      "del_poly_index_ [] [] []\n",
      "3 23\n",
      "index_bottom: 23 1\n",
      "index_top: 23 0\n",
      "in while [1] [0]\n",
      "out 1 0\n",
      "in 1 0\n",
      "del_poly_index_ [] [] []\n",
      "4 23\n",
      "1 24\n",
      "2 24\n",
      "3 24\n",
      "4 24\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "1 27\n",
      "3 27\n",
      "1 28\n",
      "2 28\n",
      "3 28\n",
      "4 28\n",
      "1 29\n",
      "2 29\n",
      "3 29\n",
      "4 29\n",
      "1 30\n",
      "2 30\n",
      "index_right: 30 1\n",
      "index_right: 30 2\n",
      "index_left: 30 0\n",
      "index_left: 30 4\n",
      "index_left: 30 5\n",
      "in while [2, 1] [5, 4, 0]\n",
      "2 5\n",
      "image30 right matched \n",
      "merged\n",
      "The #polygon= 1\n",
      "in while [1] [4, 0]\n",
      "1 4\n",
      "1 0\n",
      "image30 right matched \n",
      "merged\n",
      "The #polygon= 1\n",
      "del_poly_index_ [2, 1] [5, 0] [1.0, 1.0]\n",
      "3 30\n",
      "4 30\n",
      "1 31\n",
      "2 31\n",
      "3 31\n",
      "4 31\n",
      "1 32\n",
      "2 32\n",
      "3 32\n",
      "4 32\n",
      "1 34\n",
      "2 34\n",
      "index_right: 34 3\n",
      "index_left: 34 0\n",
      "index_left: 34 3\n",
      "in while [3] [3, 0]\n",
      "3 3\n",
      "image34 right matched \n",
      "merged\n",
      "The #polygon= 1\n",
      "del_poly_index_ [3] [3] [1.0]\n",
      "3 34\n",
      "index_bottom: 34 1\n",
      "index_top: 34 2\n",
      "in while [1] [2]\n",
      "out 1 2\n",
      "in 1 2\n",
      "image34 bottom matched \n",
      "merged\n",
      "The #polygon= 1\n",
      "del_poly_index_ [1] [2] [1.0]\n",
      "4 34\n",
      "1 35\n",
      "2 35\n",
      "3 35\n",
      "index_bottom: 35 1\n",
      "index_top: 35 2\n",
      "in while [1] [2]\n",
      "out 1 2\n",
      "in 1 2\n",
      "image35 bottom matched \n",
      "merged\n",
      "The #polygon= 1\n",
      "del_poly_index_ [1] [2] [1.0]\n",
      "4 35\n",
      "1 39\n",
      "3 39\n",
      "1 40\n",
      "2 40\n",
      "3 40\n",
      "4 40\n",
      "1 41\n",
      "2 41\n",
      "3 41\n",
      "4 41\n",
      "1 42\n",
      "2 42\n",
      "3 42\n",
      "4 42\n",
      "combined_polygons done and saved in polygons_combined.json\n",
      "\n",
      "combined file readed\n",
      "Annotations for the image 08_01_01.jpg have been merged and saved in coco_08_01_01.json\n",
      "\n",
      "08_01_01 ended............\n",
      "08_01_02 started............\n",
      "Image size: (8000, 6000, 3)\n",
      "#Rows: 8  #cols: 6\n",
      "image splited in 48 patches and saved in split_images.\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 1.8ms\n",
      "1: 640x640 (no detections), 1.8ms\n",
      "2: 640x640 (no detections), 1.8ms\n",
      "3: 640x640 (no detections), 1.8ms\n",
      "4: 640x640 1 fruitlet, 1.8ms\n",
      "5: 640x640 (no detections), 1.8ms\n",
      "6: 640x640 2 fruitlets, 1.8ms\n",
      "7: 640x640 (no detections), 1.8ms\n",
      "8: 640x640 (no detections), 1.8ms\n",
      "9: 640x640 2 fruitlets, 1.8ms\n",
      "10: 640x640 1 fruitlet, 1.8ms\n",
      "11: 640x640 (no detections), 1.8ms\n",
      "12: 640x640 (no detections), 1.8ms\n",
      "13: 640x640 (no detections), 1.8ms\n",
      "14: 640x640 1 fruitlet, 1.8ms\n",
      "15: 640x640 2 fruitlets, 1.8ms\n",
      "16: 640x640 (no detections), 1.8ms\n",
      "17: 640x640 (no detections), 1.8ms\n",
      "18: 640x640 3 fruitlets, 1.8ms\n",
      "19: 640x640 4 fruitlets, 1.8ms\n",
      "20: 640x640 1 fruitlet, 1.8ms\n",
      "21: 640x640 2 fruitlets, 1.8ms\n",
      "22: 640x640 (no detections), 1.8ms\n",
      "23: 640x640 (no detections), 1.8ms\n",
      "24: 640x640 (no detections), 1.8ms\n",
      "25: 640x640 5 fruitlets, 1.8ms\n",
      "26: 640x640 (no detections), 1.8ms\n",
      "27: 640x640 (no detections), 1.8ms\n",
      "28: 640x640 (no detections), 1.8ms\n",
      "29: 640x640 1 fruitlet, 1.8ms\n",
      "30: 640x640 1 fruitlet, 1.8ms\n",
      "31: 640x640 3 fruitlets, 1.8ms\n",
      "32: 640x640 2 fruitlets, 1.8ms\n",
      "33: 640x640 (no detections), 1.8ms\n",
      "34: 640x640 (no detections), 1.8ms\n",
      "35: 640x640 (no detections), 1.8ms\n",
      "36: 640x640 (no detections), 1.8ms\n",
      "37: 640x640 (no detections), 1.8ms\n",
      "38: 640x640 (no detections), 1.8ms\n",
      "39: 640x640 (no detections), 1.8ms\n",
      "40: 640x640 (no detections), 1.8ms\n",
      "41: 640x640 (no detections), 1.8ms\n",
      "42: 640x640 (no detections), 1.8ms\n",
      "43: 640x640 (no detections), 1.8ms\n",
      "44: 640x640 (no detections), 1.8ms\n",
      "45: 640x640 (no detections), 1.8ms\n",
      "46: 640x640 (no detections), 1.8ms\n",
      "47: 640x640 (no detections), 1.8ms\n",
      "Speed: 2.5ms preprocess, 1.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "YOLO predicted BBOX for all patches and saved successfully in yolo_out_for_image_bbox_data.json.\n",
      "\n",
      "Bounding boxes merged and saved to yolo_out_for_image_bbox_data.json.\n",
      "\n",
      "SAM generated the mask for all patches and saved to polygons.json\n",
      "\n",
      "1 14\n",
      "2 14\n",
      "3 14\n",
      "4 14\n",
      "1 16\n",
      "2 16\n",
      "index_right: 16 0\n",
      "index_right: 16 1\n",
      "del_poly_index_ [] [] []\n",
      "3 16\n",
      "4 16\n",
      "1 19\n",
      "2 19\n",
      "3 19\n",
      "4 19\n",
      "1 20\n",
      "2 20\n",
      "3 20\n",
      "4 20\n",
      "1 24\n",
      "2 24\n",
      "3 24\n",
      "4 24\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "1 28\n",
      "2 28\n",
      "index_right: 28 0\n",
      "del_poly_index_ [] [] []\n",
      "3 28\n",
      "4 28\n",
      "1 29\n",
      "2 29\n",
      "index_right: 29 2\n",
      "del_poly_index_ [] [] []\n",
      "3 29\n",
      "index_bottom: 29 1\n",
      "del_poly_index_ [] [] []\n",
      "4 29\n",
      "1 30\n",
      "2 30\n",
      "3 30\n",
      "4 30\n",
      "1 31\n",
      "2 31\n",
      "3 31\n",
      "4 31\n",
      "1 35\n",
      "2 35\n",
      "3 35\n",
      "index_bottom: 35 0\n",
      "del_poly_index_ [] [] []\n",
      "4 35\n",
      "1 39\n",
      "3 39\n",
      "1 40\n",
      "2 40\n",
      "index_right: 40 0\n",
      "index_left: 40 1\n",
      "index_left: 40 2\n",
      "in while [0] [2, 1]\n",
      "0 2\n",
      "0 1\n",
      "image40 right matched \n",
      "merged\n",
      "The #polygon= 1\n",
      "del_poly_index_ [0] [1] [1.0]\n",
      "3 40\n",
      "4 40\n",
      "1 41\n",
      "2 41\n",
      "3 41\n",
      "4 41\n",
      "1 42\n",
      "2 42\n",
      "3 42\n",
      "4 42\n",
      "combined_polygons done and saved in polygons_combined.json\n",
      "\n",
      "combined file readed\n",
      "Annotations for the image 08_01_02.jpg have been merged and saved in coco_08_01_02.json\n",
      "\n",
      "08_01_02 ended............\n",
      "file:coco_08_01_01.json to 08_01_01.json\n",
      "file:coco_08_01_02.json to 08_01_02.json\n",
      "file:coco_08_01_03.json to 08_01_03.json\n",
      "\n",
      "Total number of annotation id's are varified!!!!!\n",
      "annotation combination of 3 images is done and saved in combined_mask_visit08.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# give the input image paths(which needs to be annotated)\n",
    "# visit name\n",
    "# yolo model weight path\n",
    "!python yolo_sam_annotator/main.py 'visit_08_04302024' '08' 'runs/detect/train6/weights/best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mangosense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
